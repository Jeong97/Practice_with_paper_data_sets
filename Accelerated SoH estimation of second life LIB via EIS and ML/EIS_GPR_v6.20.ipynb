{"cells":[{"cell_type":"markdown","metadata":{"id":"qLIFDIQ4fY25"},"source":["## Model F: EIS Gaussian Process Regression: With EIS Data from Paper # 23\n","#### Including SOC & Temp as Input\n","#### K-Fold Implementation segregated by Cell Number\n","EIS GPR v6.20"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":1023,"status":"ok","timestamp":1714706834390,"user":{"displayName":"Faris","userId":"05186403845980927608"},"user_tz":-540},"id":"oSjWTHWrfY28"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{},"source":["#### Reading the Data"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Cell_Name</th>\n","      <th>SoH</th>\n","      <th>SoH_Actual</th>\n","      <th>Temp</th>\n","      <th>SoC</th>\n","      <th>Unnamed: 5</th>\n","      <th>Fx10000</th>\n","      <th>Fx7943</th>\n","      <th>Fx6310</th>\n","      <th>Fx5012</th>\n","      <th>...</th>\n","      <th>Unnamed: 179</th>\n","      <th>Unnamed: 180</th>\n","      <th>Unnamed: 181</th>\n","      <th>HF3_1.4A</th>\n","      <th>HF3_1.2A</th>\n","      <th>HF3_1.0A</th>\n","      <th>HF3_0.8A</th>\n","      <th>HF3_0.6A</th>\n","      <th>HF3_0.4A</th>\n","      <th>HF3_0.3A</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>95</td>\n","      <td>95.05</td>\n","      <td>15</td>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>0.02995</td>\n","      <td>0.02827</td>\n","      <td>0.02704</td>\n","      <td>0.02599</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.00088</td>\n","      <td>0.000467</td>\n","      <td>0.000318</td>\n","      <td>0.00024</td>\n","      <td>0.000188</td>\n","      <td>0.000147</td>\n","      <td>0.000128</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>95</td>\n","      <td>95.05</td>\n","      <td>15</td>\n","      <td>20</td>\n","      <td>NaN</td>\n","      <td>0.03001</td>\n","      <td>0.02843</td>\n","      <td>0.02716</td>\n","      <td>0.02606</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.00088</td>\n","      <td>0.000467</td>\n","      <td>0.000318</td>\n","      <td>0.00024</td>\n","      <td>0.000188</td>\n","      <td>0.000147</td>\n","      <td>0.000128</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>95</td>\n","      <td>95.05</td>\n","      <td>15</td>\n","      <td>50</td>\n","      <td>NaN</td>\n","      <td>0.02965</td>\n","      <td>0.02803</td>\n","      <td>0.02671</td>\n","      <td>0.02562</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.00088</td>\n","      <td>0.000467</td>\n","      <td>0.000318</td>\n","      <td>0.00024</td>\n","      <td>0.000188</td>\n","      <td>0.000147</td>\n","      <td>0.000128</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>95</td>\n","      <td>95.05</td>\n","      <td>15</td>\n","      <td>70</td>\n","      <td>NaN</td>\n","      <td>0.02960</td>\n","      <td>0.02800</td>\n","      <td>0.02668</td>\n","      <td>0.02549</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.00088</td>\n","      <td>0.000467</td>\n","      <td>0.000318</td>\n","      <td>0.00024</td>\n","      <td>0.000188</td>\n","      <td>0.000147</td>\n","      <td>0.000128</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>95</td>\n","      <td>95.05</td>\n","      <td>15</td>\n","      <td>95</td>\n","      <td>NaN</td>\n","      <td>0.02958</td>\n","      <td>0.02797</td>\n","      <td>0.02667</td>\n","      <td>0.02556</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.00088</td>\n","      <td>0.000467</td>\n","      <td>0.000318</td>\n","      <td>0.00024</td>\n","      <td>0.000188</td>\n","      <td>0.000147</td>\n","      <td>0.000128</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 189 columns</p>\n","</div>"],"text/plain":["   Cell_Name  SoH  SoH_Actual  Temp  SoC  Unnamed: 5  Fx10000   Fx7943  \\\n","0          2   95       95.05    15    5         NaN  0.02995  0.02827   \n","1          2   95       95.05    15   20         NaN  0.03001  0.02843   \n","2          2   95       95.05    15   50         NaN  0.02965  0.02803   \n","3          2   95       95.05    15   70         NaN  0.02960  0.02800   \n","4          2   95       95.05    15   95         NaN  0.02958  0.02797   \n","\n","    Fx6310   Fx5012  ...  Unnamed: 179  Unnamed: 180  Unnamed: 181  HF3_1.4A  \\\n","0  0.02704  0.02599  ...           NaN           NaN           NaN   0.00088   \n","1  0.02716  0.02606  ...           NaN           NaN           NaN   0.00088   \n","2  0.02671  0.02562  ...           NaN           NaN           NaN   0.00088   \n","3  0.02668  0.02549  ...           NaN           NaN           NaN   0.00088   \n","4  0.02667  0.02556  ...           NaN           NaN           NaN   0.00088   \n","\n","   HF3_1.2A  HF3_1.0A  HF3_0.8A  HF3_0.6A  HF3_0.4A  HF3_0.3A  \n","0  0.000467  0.000318   0.00024  0.000188  0.000147  0.000128  \n","1  0.000467  0.000318   0.00024  0.000188  0.000147  0.000128  \n","2  0.000467  0.000318   0.00024  0.000188  0.000147  0.000128  \n","3  0.000467  0.000318   0.00024  0.000188  0.000147  0.000128  \n","4  0.000467  0.000318   0.00024  0.000188  0.000147  0.000128  \n","\n","[5 rows x 189 columns]"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["# Extract the .csv file from its location\n","WholeDataRealSOH = pd.read_csv(\"G:\\\\My Drive\\\\Faris' Work\\\\KAIST\\\\NICE Lab\\\\Battery Data\\\\5Ah LG Cells Dataset - Paper 23\\\\WholeDataRealSOH csv.csv\") \n","\n","# Display part of the data\n","WholeDataRealSOH.head(5)"]},{"cell_type":"markdown","metadata":{},"source":["#### Selecting specific features\n","Using All 61 Frequency Points"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Cell_Name</th>\n","      <th>SoH_Actual</th>\n","      <th>Temp</th>\n","      <th>SoC</th>\n","      <th>Fx10000</th>\n","      <th>Fx7943</th>\n","      <th>Fx6310</th>\n","      <th>Fx5012</th>\n","      <th>Fx3981</th>\n","      <th>Fx3162</th>\n","      <th>...</th>\n","      <th>HF2_1500s</th>\n","      <th>HF2_1750s</th>\n","      <th>HF2_2000s</th>\n","      <th>HF3_1.4A</th>\n","      <th>HF3_1.2A</th>\n","      <th>HF3_1.0A</th>\n","      <th>HF3_0.8A</th>\n","      <th>HF3_0.6A</th>\n","      <th>HF3_0.4A</th>\n","      <th>HF3_0.3A</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>95.05</td>\n","      <td>15</td>\n","      <td>5</td>\n","      <td>0.02995</td>\n","      <td>0.02827</td>\n","      <td>0.02704</td>\n","      <td>0.02599</td>\n","      <td>0.02499</td>\n","      <td>0.02480</td>\n","      <td>...</td>\n","      <td>0.56494</td>\n","      <td>0.43828</td>\n","      <td>0.33776</td>\n","      <td>0.00088</td>\n","      <td>0.000467</td>\n","      <td>0.000318</td>\n","      <td>0.00024</td>\n","      <td>0.000188</td>\n","      <td>0.000147</td>\n","      <td>0.000128</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>95.05</td>\n","      <td>15</td>\n","      <td>20</td>\n","      <td>0.03001</td>\n","      <td>0.02843</td>\n","      <td>0.02716</td>\n","      <td>0.02606</td>\n","      <td>0.02506</td>\n","      <td>0.02487</td>\n","      <td>...</td>\n","      <td>0.56494</td>\n","      <td>0.43828</td>\n","      <td>0.33776</td>\n","      <td>0.00088</td>\n","      <td>0.000467</td>\n","      <td>0.000318</td>\n","      <td>0.00024</td>\n","      <td>0.000188</td>\n","      <td>0.000147</td>\n","      <td>0.000128</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>95.05</td>\n","      <td>15</td>\n","      <td>50</td>\n","      <td>0.02965</td>\n","      <td>0.02803</td>\n","      <td>0.02671</td>\n","      <td>0.02562</td>\n","      <td>0.02464</td>\n","      <td>0.02443</td>\n","      <td>...</td>\n","      <td>0.56494</td>\n","      <td>0.43828</td>\n","      <td>0.33776</td>\n","      <td>0.00088</td>\n","      <td>0.000467</td>\n","      <td>0.000318</td>\n","      <td>0.00024</td>\n","      <td>0.000188</td>\n","      <td>0.000147</td>\n","      <td>0.000128</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows × 94 columns</p>\n","</div>"],"text/plain":["   Cell_Name  SoH_Actual  Temp  SoC  Fx10000   Fx7943   Fx6310   Fx5012  \\\n","0          2       95.05    15    5  0.02995  0.02827  0.02704  0.02599   \n","1          2       95.05    15   20  0.03001  0.02843  0.02716  0.02606   \n","2          2       95.05    15   50  0.02965  0.02803  0.02671  0.02562   \n","\n","    Fx3981   Fx3162  ...  HF2_1500s  HF2_1750s  HF2_2000s  HF3_1.4A  HF3_1.2A  \\\n","0  0.02499  0.02480  ...    0.56494    0.43828    0.33776   0.00088  0.000467   \n","1  0.02506  0.02487  ...    0.56494    0.43828    0.33776   0.00088  0.000467   \n","2  0.02464  0.02443  ...    0.56494    0.43828    0.33776   0.00088  0.000467   \n","\n","   HF3_1.0A  HF3_0.8A  HF3_0.6A  HF3_0.4A  HF3_0.3A  \n","0  0.000318   0.00024  0.000188  0.000147  0.000128  \n","1  0.000318   0.00024  0.000188  0.000147  0.000128  \n","2  0.000318   0.00024  0.000188  0.000147  0.000128  \n","\n","[3 rows x 94 columns]"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["# Selecting All 61 Frequency Points (10kHz ~ 0.01Hz)\n","FP61 = ['Fx10000','Fx7943','Fx6310','Fx5012','Fx3981','Fx3162','Fx2512','Fx1995','Fx1585','Fx1259',\n","        'Fx1000','Fx794.3','Fx631','Fx501.2','Fx398.1','Fx316.2','Fx251.2','Fx199.5','Fx158.5','Fx125.9',\n","        'Fx100','Fx79.43','Fx63.1','Fx52','Fx39.81','Fx31.62','Fx25.12','Fx19.95','Fx15.85','Fx12.59',\n","        'Fx10','Fx7.943','Fx6.31','Fx5.012','Fx3.981','Fx3.162','Fx2.512','Fx1.995','Fx1.585','Fx1.259',\n","        'Fx1','Fx0.7943','Fx0.631','Fx0.5012','Fx0.3981','Fx0.3162','Fx0.2512','Fx0.1995','Fx0.1585','Fx0.1259',\n","        'Fx0.1','Fx0.07943','Fx0.0631','Fx0.05012','Fx0.03981','Fx0.03162','Fx0.02512','Fx0.01995','Fx0.01585','Fx0.01259','Fx0.01',\n","        'Fy10000','Fy7943','Fy6310','Fy5012','Fy3981','Fy3162','Fy2512','Fy1995','Fy1585','Fy1259',\n","        'Fy1000','Fy794.3','Fy631','Fy501.2','Fy398.1','Fy316.2','Fy251.2','Fy199.5','Fy158.5','Fy125.9',\n","        'Fy100','Fy79.43','Fy63.1','Fy52','Fy39.81','Fy31.62','Fy25.12','Fy19.95','Fy15.85','Fy12.59',\n","        'Fy10','Fy7.943','Fy6.31','Fy5.012','Fy3.981','Fy3.162','Fy2.512','Fy1.995','Fy1.585','Fy1.259',\n","        'Fy1','Fy0.7943','Fy0.631','Fy0.5012','Fy0.3981','Fy0.3162','Fy0.2512','Fy0.1995','Fy0.1585','Fy0.1259',\n","        'Fy0.1','Fy0.07943','Fy0.0631','Fy0.05012','Fy0.03981','Fy0.03162','Fy0.02512','Fy0.01995','Fy0.01585','Fy0.01259','Fy0.01']\n","\n","# Selecting 51 High Frequency Points (10kHz ~ 0.1Hz)\n","FP51 = ['Fx10000','Fx7943','Fx6310','Fx5012','Fx3981','Fx3162','Fx2512','Fx1995','Fx1585','Fx1259',\n","        'Fx1000','Fx794.3','Fx631','Fx501.2','Fx398.1','Fx316.2','Fx251.2','Fx199.5','Fx158.5','Fx125.9',\n","        'Fx100','Fx79.43','Fx63.1','Fx52','Fx39.81','Fx31.62','Fx25.12','Fx19.95','Fx15.85','Fx12.59',\n","        'Fx10','Fx7.943','Fx6.31','Fx5.012','Fx3.981','Fx3.162','Fx2.512','Fx1.995','Fx1.585','Fx1.259',\n","        'Fx1','Fx0.7943','Fx0.631','Fx0.5012','Fx0.3981','Fx0.3162','Fx0.2512','Fx0.1995','Fx0.1585','Fx0.1259',\n","        'Fx0.1',\n","        'Fy10000','Fy7943','Fy6310','Fy5012','Fy3981','Fy3162','Fy2512','Fy1995','Fy1585','Fy1259',\n","        'Fy1000','Fy794.3','Fy631','Fy501.2','Fy398.1','Fy316.2','Fy251.2','Fy199.5','Fy158.5','Fy125.9',\n","        'Fy100','Fy79.43','Fy63.1','Fy52','Fy39.81','Fy31.62','Fy25.12','Fy19.95','Fy15.85','Fy12.59',\n","        'Fy10','Fy7.943','Fy6.31','Fy5.012','Fy3.981','Fy3.162','Fy2.512','Fy1.995','Fy1.585','Fy1.259',\n","        'Fy1','Fy0.7943','Fy0.631','Fy0.5012','Fy0.3981','Fy0.3162','Fy0.2512','Fy0.1995','Fy0.1585','Fy0.1259',\n","        'Fy0.1']\n","\n","# Selecting 51 High Frequency Points (10kHz ~ 0.3Hz)\n","FP46 = ['Fx10000','Fx7943','Fx6310','Fx5012','Fx3981','Fx3162','Fx2512','Fx1995','Fx1585','Fx1259',\n","        'Fx1000','Fx794.3','Fx631','Fx501.2','Fx398.1','Fx316.2','Fx251.2','Fx199.5','Fx158.5','Fx125.9',\n","        'Fx100','Fx79.43','Fx63.1','Fx52','Fx39.81','Fx31.62','Fx25.12','Fx19.95','Fx15.85','Fx12.59',\n","        'Fx10','Fx7.943','Fx6.31','Fx5.012','Fx3.981','Fx3.162','Fx2.512','Fx1.995','Fx1.585','Fx1.259',\n","        'Fx1','Fx0.7943','Fx0.631','Fx0.5012','Fx0.3981','Fx0.3162',\n","        'Fy10000','Fy7943','Fy6310','Fy5012','Fy3981','Fy3162','Fy2512','Fy1995','Fy1585','Fy1259',\n","        'Fy1000','Fy794.3','Fy631','Fy501.2','Fy398.1','Fy316.2','Fy251.2','Fy199.5','Fy158.5','Fy125.9',\n","        'Fy100','Fy79.43','Fy63.1','Fy52','Fy39.81','Fy31.62','Fy25.12','Fy19.95','Fy15.85','Fy12.59',\n","        'Fy10','Fy7.943','Fy6.31','Fy5.012','Fy3.981','Fy3.162','Fy2.512','Fy1.995','Fy1.585','Fy1.259',\n","        'Fy1','Fy0.7943','Fy0.631','Fy0.5012','Fy0.3981','Fy0.3162']\n","\n","# Selecting 41 High Frequency Points (10kHz ~ 1Hz)\n","FP41 = ['Fx10000','Fx7943','Fx6310','Fx5012','Fx3981','Fx3162','Fx2512','Fx1995','Fx1585','Fx1259',\n","        'Fx1000','Fx794.3','Fx631','Fx501.2','Fx398.1','Fx316.2','Fx251.2','Fx199.5','Fx158.5','Fx125.9',\n","        'Fx100','Fx79.43','Fx63.1','Fx52','Fx39.81','Fx31.62','Fx25.12','Fx19.95','Fx15.85','Fx12.59',\n","        'Fx10','Fx7.943','Fx6.31','Fx5.012','Fx3.981','Fx3.162','Fx2.512','Fx1.995','Fx1.585','Fx1.259',\n","        'Fx1',\n","        'Fy10000','Fy7943','Fy6310','Fy5012','Fy3981','Fy3162','Fy2512','Fy1995','Fy1585','Fy1259',\n","        'Fy1000','Fy794.3','Fy631','Fy501.2','Fy398.1','Fy316.2','Fy251.2','Fy199.5','Fy158.5','Fy125.9',\n","        'Fy100','Fy79.43','Fy63.1','Fy52','Fy39.81','Fy31.62','Fy25.12','Fy19.95','Fy15.85','Fy12.59',\n","        'Fy10','Fy7.943','Fy6.31','Fy5.012','Fy3.981','Fy3.162','Fy2.512','Fy1.995','Fy1.585','Fy1.259',\n","        'Fy1']\n","\n","# Selecting 41 High Frequency Points (10kHz ~ 2Hz)\n","FP38 = ['Fx10000','Fx7943','Fx6310','Fx5012','Fx3981','Fx3162','Fx2512','Fx1995','Fx1585','Fx1259',\n","        'Fx1000','Fx794.3','Fx631','Fx501.2','Fx398.1','Fx316.2','Fx251.2','Fx199.5','Fx158.5','Fx125.9',\n","        'Fx100','Fx79.43','Fx63.1','Fx52','Fx39.81','Fx31.62','Fx25.12','Fx19.95','Fx15.85','Fx12.59',\n","        'Fx10','Fx7.943','Fx6.31','Fx5.012','Fx3.981','Fx3.162','Fx2.512','Fx1.995',\n","        'Fy10000','Fy7943','Fy6310','Fy5012','Fy3981','Fy3162','Fy2512','Fy1995','Fy1585','Fy1259',\n","        'Fy1000','Fy794.3','Fy631','Fy501.2','Fy398.1','Fy316.2','Fy251.2','Fy199.5','Fy158.5','Fy125.9',\n","        'Fy100','Fy79.43','Fy63.1','Fy52','Fy39.81','Fy31.62','Fy25.12','Fy19.95','Fy15.85','Fy12.59',\n","        'Fy10','Fy7.943','Fy6.31','Fy5.012','Fy3.981','Fy3.162','Fy2.512','Fy1.995']\n","\n","# Selecting 34 High Frequency Points (10kHz ~ 5Hz)\n","FP34 = ['Fx10000','Fx7943','Fx6310','Fx5012','Fx3981','Fx3162','Fx2512','Fx1995','Fx1585','Fx1259',\n","        'Fx1000','Fx794.3','Fx631','Fx501.2','Fx398.1','Fx316.2','Fx251.2','Fx199.5','Fx158.5','Fx125.9',\n","        'Fx100','Fx79.43','Fx63.1','Fx52','Fx39.81','Fx31.62','Fx25.12','Fx19.95','Fx15.85','Fx12.59',\n","        'Fx10','Fx7.943','Fx6.31','Fx5.012',\n","        'Fy10000','Fy7943','Fy6310','Fy5012','Fy3981','Fy3162','Fy2512','Fy1995','Fy1585','Fy1259',\n","        'Fy1000','Fy794.3','Fy631','Fy501.2','Fy398.1','Fy316.2','Fy251.2','Fy199.5','Fy158.5','Fy125.9',\n","        'Fy100','Fy79.43','Fy63.1','Fy52','Fy39.81','Fy31.62','Fy25.12','Fy19.95','Fy15.85','Fy12.59',\n","        'Fy10','Fy7.943','Fy6.31','Fy5.012']\n","\n","# Selecting 31 High Frequency Points (10kHz ~ 10Hz)\n","FP31 = ['Fx10000','Fx7943','Fx6310','Fx5012','Fx3981','Fx3162','Fx2512','Fx1995','Fx1585','Fx1259',\n","        'Fx1000','Fx794.3','Fx631','Fx501.2','Fx398.1','Fx316.2','Fx251.2','Fx199.5','Fx158.5','Fx125.9',\n","        'Fx100','Fx79.43','Fx63.1','Fx52','Fx39.81','Fx31.62','Fx25.12','Fx19.95','Fx15.85','Fx12.59',\n","        'Fx10',\n","        'Fy10000','Fy7943','Fy6310','Fy5012','Fy3981','Fy3162','Fy2512','Fy1995','Fy1585','Fy1259',\n","        'Fy1000','Fy794.3','Fy631','Fy501.2','Fy398.1','Fy316.2','Fy251.2','Fy199.5','Fy158.5','Fy125.9',\n","        'Fy100','Fy79.43','Fy63.1','Fy52','Fy39.81','Fy31.62','Fy25.12','Fy19.95','Fy15.85','Fy12.59',\n","        'Fy10']\n","\n","# Selecting 28 High Frequency Points (10kHz ~ 20Hz)\n","FP28 = ['Fx10000','Fx7943','Fx6310','Fx5012','Fx3981','Fx3162','Fx2512','Fx1995','Fx1585','Fx1259',\n","        'Fx1000','Fx794.3','Fx631','Fx501.2','Fx398.1','Fx316.2','Fx251.2','Fx199.5','Fx158.5','Fx125.9',\n","        'Fx100','Fx79.43','Fx63.1','Fx52','Fx39.81','Fx31.62','Fx25.12','Fx19.95',\n","        'Fy10000','Fy7943','Fy6310','Fy5012','Fy3981','Fy3162','Fy2512','Fy1995','Fy1585','Fy1259',\n","        'Fy1000','Fy794.3','Fy631','Fy501.2','Fy398.1','Fy316.2','Fy251.2','Fy199.5','Fy158.5','Fy125.9',\n","        'Fy100','Fy79.43','Fy63.1','Fy52','Fy39.81','Fy31.62','Fy25.12','Fy19.95']\n","\n","# Selecting 24 High Frequency Points (10kHz ~ 50Hz)\n","FP24 = ['Fx10000','Fx7943','Fx6310','Fx5012','Fx3981','Fx3162','Fx2512','Fx1995','Fx1585','Fx1259',\n","        'Fx1000','Fx794.3','Fx631','Fx501.2','Fx398.1','Fx316.2','Fx251.2','Fx199.5','Fx158.5','Fx125.9',\n","        'Fx100','Fx79.43','Fx63.1','Fx52',\n","        'Fy10000','Fy7943','Fy6310','Fy5012','Fy3981','Fy3162','Fy2512','Fy1995','Fy1585','Fy1259',\n","        'Fy1000','Fy794.3','Fy631','Fy501.2','Fy398.1','Fy316.2','Fy251.2','Fy199.5','Fy158.5','Fy125.9',\n","        'Fy100','Fy79.43','Fy63.1','Fy52']\n","\n","# Selecting 7 best Frequency Points\n","FP7 = ['Fx_1','Fx_2','Fx_3','Fx_4','Fx_5','Fx_6','Fx_7','Fy_1','Fy_2','Fy_3','Fy_4','Fy_5','Fy_6','Fy_7']\n","\n","# Selecting Custom Frequency Ranges: (x: 10kHz ~ 100Hz) (y: 1Hz ~ 0.01Hz)\n","FPc = ['Fx10000','Fx7943','Fx6310','Fx5012','Fx3981','Fx3162','Fx2512','Fx1995','Fx1585','Fx1259',\n","        'Fx1000','Fx794.3','Fx631','Fx501.2','Fx398.1','Fx316.2','Fx251.2','Fx199.5','Fx158.5','Fx125.9',\n","        'Fx100','Fx79.43','Fx63.1','Fx52','Fx39.81','Fx31.62','Fx25.12','Fx19.95','Fx15.85','Fx12.59',\n","        'Fx10',\n","        'Fy1','Fy0.7943','Fy0.631','Fy0.5012','Fy0.3981','Fy0.3162','Fy0.2512','Fy0.1995','Fy0.1585','Fy0.1259',\n","        'Fy0.1','Fy0.07943','Fy0.0631','Fy0.05012','Fy0.03981','Fy0.03162','Fy0.02512','Fy0.01995','Fy0.01585','Fy0.01259','Fy0.01']\n","\n","# Selecting Custom Frequency Ranges (x: 10kHz ~ 100Hz)\n","FPc1 = ['Fx10000','Fx7943','Fx6310','Fx5012','Fx3981','Fx3162','Fx2512','Fx1995','Fx1585','Fx1259',\n","        'Fx1000','Fx794.3','Fx631','Fx501.2','Fx398.1','Fx316.2','Fx251.2','Fx199.5','Fx158.5','Fx125.9',\n","        'Fx100','Fx79.43','Fx63.1','Fx52','Fx39.81','Fx31.62','Fx25.12','Fx19.95','Fx15.85','Fx12.59',\n","        'Fx10']\n","\n","# Selecting Custom Frequency Ranges (x: 10kHz ~ 1kHz)\n","FPc2 = ['Fx10000','Fx7943','Fx6310','Fx5012','Fx3981','Fx3162','Fx2512','Fx1995','Fx1585','Fx1259',\n","        'Fx1000']\n","\n","# Selecting Custom Frequency Ranges (x: 10kHz ~ 100Hz) (y: 10kHz ~ 1kHz)\n","FPc3 = ['Fx10000','Fx7943','Fx6310','Fx5012','Fx3981','Fx3162','Fx2512','Fx1995','Fx1585','Fx1259',\n","        'Fx1000','Fx794.3','Fx631','Fx501.2','Fx398.1','Fx316.2','Fx251.2','Fx199.5','Fx158.5','Fx125.9',\n","        'Fx100','Fx79.43','Fx63.1','Fx52','Fx39.81','Fx31.62','Fx25.12','Fx19.95','Fx15.85','Fx12.59',\n","        'Fx10',\n","        'Fy10000','Fy7943','Fy6310','Fy5012','Fy3981','Fy3162','Fy2512','Fy1995','Fy1585','Fy1259',\n","        'Fy1000']\n","\n","# ALL Health Features\n","HF1 = ['HF1_4.0V','HF1_3.9V','HF1_3.8V','HF1_3.7V','HF1_3.6V','HF1_3.5V','HF1_3.4V']\n","HF2 = ['HF2_250s','HF2_500s','HF2_750s','HF2_1000s','HF2_1250s','HF2_1500s','HF2_1750s','HF2_2000s']\n","HF3 = ['HF3_1.4A','HF3_1.2A','HF3_1.0A','HF3_0.8A','HF3_0.6A','HF3_0.4A','HF3_0.3A']\n","\n","# Choose the Frequency Points\n","FP = FP34\n","FPx = [value for value in FP if value.startswith('Fx')]\n","FPy = [value for value in FP if value.startswith('Fy')]\n","\n","# Select the specific columns needed for Implementation - Cell#, SoH, Temp, SoC, frequency points (x & y)\n","sfp = WholeDataRealSOH[['Cell_Name','SoH_Actual','Temp','SoC'] + FP + HF1 + HF2 + HF3]\n","\n","# Display part of the data\n","sfp.head(3)"]},{"cell_type":"markdown","metadata":{},"source":["#### Creating Training Samples:\n","All Cells (except test cells)"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Cell_Name</th>\n","      <th>SoH_Actual</th>\n","      <th>Temp</th>\n","      <th>SoC</th>\n","      <th>Fx10000</th>\n","      <th>Fx7943</th>\n","      <th>Fx6310</th>\n","      <th>Fx5012</th>\n","      <th>Fx3981</th>\n","      <th>Fx3162</th>\n","      <th>...</th>\n","      <th>HF2_1500s</th>\n","      <th>HF2_1750s</th>\n","      <th>HF2_2000s</th>\n","      <th>HF3_1.4A</th>\n","      <th>HF3_1.2A</th>\n","      <th>HF3_1.0A</th>\n","      <th>HF3_0.8A</th>\n","      <th>HF3_0.6A</th>\n","      <th>HF3_0.4A</th>\n","      <th>HF3_0.3A</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>15</th>\n","      <td>3</td>\n","      <td>96.21</td>\n","      <td>15</td>\n","      <td>5</td>\n","      <td>0.02958</td>\n","      <td>0.02802</td>\n","      <td>0.02667</td>\n","      <td>0.02565</td>\n","      <td>0.02467</td>\n","      <td>0.02447</td>\n","      <td>...</td>\n","      <td>0.87038</td>\n","      <td>0.75509</td>\n","      <td>0.63827</td>\n","      <td>0.000918</td>\n","      <td>0.000375</td>\n","      <td>0.000224</td>\n","      <td>0.000163</td>\n","      <td>0.00013</td>\n","      <td>0.000105</td>\n","      <td>0.000094</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>3</td>\n","      <td>96.21</td>\n","      <td>15</td>\n","      <td>20</td>\n","      <td>0.02939</td>\n","      <td>0.02783</td>\n","      <td>0.02652</td>\n","      <td>0.02546</td>\n","      <td>0.02445</td>\n","      <td>0.02425</td>\n","      <td>...</td>\n","      <td>0.87038</td>\n","      <td>0.75509</td>\n","      <td>0.63827</td>\n","      <td>0.000918</td>\n","      <td>0.000375</td>\n","      <td>0.000224</td>\n","      <td>0.000163</td>\n","      <td>0.00013</td>\n","      <td>0.000105</td>\n","      <td>0.000094</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>3</td>\n","      <td>96.21</td>\n","      <td>15</td>\n","      <td>50</td>\n","      <td>0.02928</td>\n","      <td>0.02767</td>\n","      <td>0.02640</td>\n","      <td>0.02531</td>\n","      <td>0.02431</td>\n","      <td>0.02410</td>\n","      <td>...</td>\n","      <td>0.87038</td>\n","      <td>0.75509</td>\n","      <td>0.63827</td>\n","      <td>0.000918</td>\n","      <td>0.000375</td>\n","      <td>0.000224</td>\n","      <td>0.000163</td>\n","      <td>0.00013</td>\n","      <td>0.000105</td>\n","      <td>0.000094</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows × 94 columns</p>\n","</div>"],"text/plain":["    Cell_Name  SoH_Actual  Temp  SoC  Fx10000   Fx7943   Fx6310   Fx5012  \\\n","15          3       96.21    15    5  0.02958  0.02802  0.02667  0.02565   \n","16          3       96.21    15   20  0.02939  0.02783  0.02652  0.02546   \n","17          3       96.21    15   50  0.02928  0.02767  0.02640  0.02531   \n","\n","     Fx3981   Fx3162  ...  HF2_1500s  HF2_1750s  HF2_2000s  HF3_1.4A  \\\n","15  0.02467  0.02447  ...    0.87038    0.75509    0.63827  0.000918   \n","16  0.02445  0.02425  ...    0.87038    0.75509    0.63827  0.000918   \n","17  0.02431  0.02410  ...    0.87038    0.75509    0.63827  0.000918   \n","\n","    HF3_1.2A  HF3_1.0A  HF3_0.8A  HF3_0.6A  HF3_0.4A  HF3_0.3A  \n","15  0.000375  0.000224  0.000163   0.00013  0.000105  0.000094  \n","16  0.000375  0.000224  0.000163   0.00013  0.000105  0.000094  \n","17  0.000375  0.000224  0.000163   0.00013  0.000105  0.000094  \n","\n","[3 rows x 94 columns]"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["# Creating training data (Training & Test data will use different cells)\n","train = [None] * 5\n","train[0] = (sfp['Cell_Name'] != 28) & (sfp['Cell_Name'] != 2) & (sfp['Cell_Name'] != 12) & (sfp['Cell_Name'] != 19) & (sfp['Cell_Name'] != 15)\n","train[1] = (sfp['Cell_Name'] != 29) & (sfp['Cell_Name'] != 3) & (sfp['Cell_Name'] != 23) & (sfp['Cell_Name'] != 20) & (sfp['Cell_Name'] != 17)\n","train[2] = (sfp['Cell_Name'] != 30) & (sfp['Cell_Name'] != 4) & (sfp['Cell_Name'] != 14) & (sfp['Cell_Name'] != 21) & (sfp['Cell_Name'] != 18)\n","train[3] = (sfp['Cell_Name'] != 32) & (sfp['Cell_Name'] != 5) & (sfp['Cell_Name'] != 23) & (sfp['Cell_Name'] != 25) & (sfp['Cell_Name'] != 22)\n","# train[4] = (sfp['Cell_Name'] != 31) & (sfp['Cell_Name'] != 6) & (sfp['Cell_Name'] != 13) & (sfp['Cell_Name'] != 26) & (sfp['Cell_Name'] != 24)\n","train[4] = (sfp['Cell_Name'] != 31) & (sfp['Cell_Name'] != 6) & (sfp['Cell_Name'] != 13) & (sfp['Cell_Name'] != 24)    # No 26\n","\n","sfp_train = sfp[train[0]]\n","sfp_train.head(3)"]},{"cell_type":"markdown","metadata":{},"source":["#### Creating Test Samples:"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Cell_Name</th>\n","      <th>SoH_Actual</th>\n","      <th>Temp</th>\n","      <th>SoC</th>\n","      <th>Fx10000</th>\n","      <th>Fx7943</th>\n","      <th>Fx6310</th>\n","      <th>Fx5012</th>\n","      <th>Fx3981</th>\n","      <th>Fx3162</th>\n","      <th>...</th>\n","      <th>HF2_1500s</th>\n","      <th>HF2_1750s</th>\n","      <th>HF2_2000s</th>\n","      <th>HF3_1.4A</th>\n","      <th>HF3_1.2A</th>\n","      <th>HF3_1.0A</th>\n","      <th>HF3_0.8A</th>\n","      <th>HF3_0.6A</th>\n","      <th>HF3_0.4A</th>\n","      <th>HF3_0.3A</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>95.05</td>\n","      <td>15</td>\n","      <td>5</td>\n","      <td>0.02995</td>\n","      <td>0.02827</td>\n","      <td>0.02704</td>\n","      <td>0.02599</td>\n","      <td>0.02499</td>\n","      <td>0.02480</td>\n","      <td>...</td>\n","      <td>0.56494</td>\n","      <td>0.43828</td>\n","      <td>0.33776</td>\n","      <td>0.00088</td>\n","      <td>0.000467</td>\n","      <td>0.000318</td>\n","      <td>0.00024</td>\n","      <td>0.000188</td>\n","      <td>0.000147</td>\n","      <td>0.000128</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>95.05</td>\n","      <td>15</td>\n","      <td>20</td>\n","      <td>0.03001</td>\n","      <td>0.02843</td>\n","      <td>0.02716</td>\n","      <td>0.02606</td>\n","      <td>0.02506</td>\n","      <td>0.02487</td>\n","      <td>...</td>\n","      <td>0.56494</td>\n","      <td>0.43828</td>\n","      <td>0.33776</td>\n","      <td>0.00088</td>\n","      <td>0.000467</td>\n","      <td>0.000318</td>\n","      <td>0.00024</td>\n","      <td>0.000188</td>\n","      <td>0.000147</td>\n","      <td>0.000128</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>95.05</td>\n","      <td>15</td>\n","      <td>50</td>\n","      <td>0.02965</td>\n","      <td>0.02803</td>\n","      <td>0.02671</td>\n","      <td>0.02562</td>\n","      <td>0.02464</td>\n","      <td>0.02443</td>\n","      <td>...</td>\n","      <td>0.56494</td>\n","      <td>0.43828</td>\n","      <td>0.33776</td>\n","      <td>0.00088</td>\n","      <td>0.000467</td>\n","      <td>0.000318</td>\n","      <td>0.00024</td>\n","      <td>0.000188</td>\n","      <td>0.000147</td>\n","      <td>0.000128</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows × 94 columns</p>\n","</div>"],"text/plain":["   Cell_Name  SoH_Actual  Temp  SoC  Fx10000   Fx7943   Fx6310   Fx5012  \\\n","0          2       95.05    15    5  0.02995  0.02827  0.02704  0.02599   \n","1          2       95.05    15   20  0.03001  0.02843  0.02716  0.02606   \n","2          2       95.05    15   50  0.02965  0.02803  0.02671  0.02562   \n","\n","    Fx3981   Fx3162  ...  HF2_1500s  HF2_1750s  HF2_2000s  HF3_1.4A  HF3_1.2A  \\\n","0  0.02499  0.02480  ...    0.56494    0.43828    0.33776   0.00088  0.000467   \n","1  0.02506  0.02487  ...    0.56494    0.43828    0.33776   0.00088  0.000467   \n","2  0.02464  0.02443  ...    0.56494    0.43828    0.33776   0.00088  0.000467   \n","\n","   HF3_1.0A  HF3_0.8A  HF3_0.6A  HF3_0.4A  HF3_0.3A  \n","0  0.000318   0.00024  0.000188  0.000147  0.000128  \n","1  0.000318   0.00024  0.000188  0.000147  0.000128  \n","2  0.000318   0.00024  0.000188  0.000147  0.000128  \n","\n","[3 rows x 94 columns]"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["# Creating Test Data (All Test sets have complete SOH ranges)\n","test = [None] * 5\n","test[0] = (sfp['Cell_Name'] == 28) | (sfp['Cell_Name'] == 2) | (sfp['Cell_Name'] == 12) | (sfp['Cell_Name'] == 19) | (sfp['Cell_Name'] == 15)\n","test[1] = (sfp['Cell_Name'] == 29) | (sfp['Cell_Name'] == 3) | (sfp['Cell_Name'] == 23) | (sfp['Cell_Name'] == 20) | (sfp['Cell_Name'] == 17)\n","test[2] = (sfp['Cell_Name'] == 30) | (sfp['Cell_Name'] == 4) | (sfp['Cell_Name'] == 14) | (sfp['Cell_Name'] == 21) | (sfp['Cell_Name'] == 18)\n","test[3] = (sfp['Cell_Name'] == 32) | (sfp['Cell_Name'] == 5) | (sfp['Cell_Name'] == 23) | (sfp['Cell_Name'] == 25) | (sfp['Cell_Name'] == 22)\n","# test[4] = (sfp['Cell_Name'] == 31) | (sfp['Cell_Name'] == 6) | (sfp['Cell_Name'] == 13) | (sfp['Cell_Name'] == 26) | (sfp['Cell_Name'] == 24)\n","test[4] = (sfp['Cell_Name'] == 31) | (sfp['Cell_Name'] == 6) | (sfp['Cell_Name'] == 13) | (sfp['Cell_Name'] == 24)     # No 26\n","\n","sfp_test = sfp[test[0]]\n","sfp_test.head(3)"]},{"cell_type":"markdown","metadata":{},"source":["#### GPR Model Implementation"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 5 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 6 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 8 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 9 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 11 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 12 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 17 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 18 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 19 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 20 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 21 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 25 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 26 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 34 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 35 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 38 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 39 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 40 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 44 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 46 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 48 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 49 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 59 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 61 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 62 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 66 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 70 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n"," Training Time = 1427 sec\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 2 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 3 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 5 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 6 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 9 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 10 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 11 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 13 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 14 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 15 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 18 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 22 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 23 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 26 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 32 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 38 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 39 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 53 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 56 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 57 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 62 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 65 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 69 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n"," Training Time = 1516 sec\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 2 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 3 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 5 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 8 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 10 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 11 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 13 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 22 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 24 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 27 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 46 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 51 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 56 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 59 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 61 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 70 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n"," Training Time = 1280 sec\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 3 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 4 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 6 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 8 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 9 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 10 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 12 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 16 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 18 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 21 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 23 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 24 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 30 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 40 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 56 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 62 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 66 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 67 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 69 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 70 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n"," Training Time = 1476 sec\n","\n","\n"," Training Time = 1671 sec\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 5 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 8 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 10 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 13 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 14 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 16 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 17 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 18 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 19 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 23 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 28 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 30 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 37 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 45 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 51 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 54 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 55 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 56 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 58 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 60 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 62 of parameter k1__k2__length_scale is close to the specified lower bound 0.05. Decreasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 63 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n","c:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 64 of parameter k1__k2__length_scale is close to the specified upper bound 1000000.0. Increasing the bound and calling fit again may find a better value.\n","  warnings.warn(\n"]}],"source":["from sklearn.gaussian_process import GaussianProcessRegressor\n","from sklearn.gaussian_process.kernels import RBF, WhiteKernel, Matern, ConstantKernel\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import root_mean_squared_error\n","import time\n","\n","# Initalizing arrays to store various Metrics\n","kernelHP = [None] * 5\n","MAE = [None] * 5\n","MSE = [None] * 5\n","RMSE = [None] * 5\n","R2Trn = [None] * 5\n","R2Test = [None] * 5\n","TrTime = [None] * 5\n","mean_prediction = [None] * 5\n","Error = [None] * 5\n","\n","for i in range(len(test)):\n","    \n","    # Creating Training and Test Data\n","    sfp_train = sfp[train[i]]\n","    sfp_test = sfp[test[i]] \n","\n","    # Converting training samples to np arrays for GPR\n","    X_train = np.asanyarray(sfp_train[['Temp','SoC','HF1_4.0V'] + FP])\n","    Y_train = np.asanyarray(sfp_train[['SoH_Actual']])\n","    \n","    # Converting test samples to np arrays for GPR\n","    X_test = np.asanyarray(sfp_test[['Temp','SoC','HF1_4.0V'] + FP])\n","    Y_test = np.asanyarray(sfp_test[['SoH_Actual']])\n","\n","    # Initial Values for Kernels\n","    gpr_input_size = X_train.shape[1]\n","    MlengthScale = [1.0] * gpr_input_size\n","    # MlengthScale = [55.4, 177, 1.61e+03, 0.141, 0.022, 1.04e+04, 4.72e+03, 478, 20.9, 0.00417, 2.01e+04, 3.51, 731, 1e+05, 4.02, 0.00616, 1.13e+03, 13.9, 6.65, 575, 0.497, 4.26e+03, 0.0114, 12.3, 4.28e+03, 1e+05, 5.25e+03, 5.73e+03, 1e+05, 647, 24.5, 322, 431, 0.0552, 7.51e+03, 503, 4.37e+04, 1.38e+04, 1.38e+04, 3.46e+04, 78.6, 49.2, 34.7, 1e+05, 108, 2.04e+03, 7.74e+03, 2.44e+04, 96.4, 2.48e+03, 78.2, 2.36e+04, 146, 953, 695, 145, 159, 102, 103, 1e+05, 228, 156, 9.54e+03, 645, 392, 288, 3.56e+04, 5.29e+03, 6.15e+04, 1e+05, 9.98e+04, 124, 1e+05, 43.4, 6.22e+04, 20.3, 1.34e+04, 22.4, 28.4, 767, 1.11e+03, 14.4, 1e+05, 0.041, 1e+05, 19.6, 1e+05, 4.44e+04, 0.0117, 0.00848, 15.5, 40.1, 1.43e+03, 774, 0.0226, 0.0174, 58.8, 0.102, 19.1, 2.78e+03, 487, 45.3, 2.8e+03, 43.3, 82.6, 10.3, 14.5, 1e+05, 92.8, 48.1, 1e+05, 21.9, 1e+05, 6.67e+04, 59, 72.5, 1e+05, 1e+05, 153, 8.88e+04, 195, 930, 0.0352, 15.6]\n","    MlengthScaleBounds = [(5e-2, 1e6)] * gpr_input_size           # Setting the Range directly adjusts the smoothnes of the prediction - Underfitting/Overfitting (Higher -> Underfit)\n","    # MlengthScaleBounds = \"fixed\"\n","    \n","    # Initiating Kernels and GPR\n","    Kernel = 10**2 * Matern(length_scale=MlengthScale, length_scale_bounds=MlengthScaleBounds, nu=2.5) + WhiteKernel(noise_level=1.0, noise_level_bounds=(1e-1, 1e1))\n","    gaussian_process = GaussianProcessRegressor(kernel=Kernel, n_restarts_optimizer=66)             #, random_state = 7 : 91\n","\n","    # Training the data and optimizing hyperparameters\n","    start = time.time()\n","    gaussian_process.fit(X_train, Y_train)\n","    stop = time.time()\n","\n","    # Predicting SoH from Test Data\n","    mean_prediction[i] = gaussian_process.predict(X_test, return_std=False)\n","    Error[i] = np.subtract(np.squeeze(Y_test), mean_prediction[i])\n","\n","    # Saving various Metrics\n","    kernelHP[i] = gaussian_process.kernel_\n","    MAE[i] = mean_absolute_error(Y_test, mean_prediction[i])\n","    MSE[i] = mean_squared_error(Y_test, mean_prediction[i])\n","    RMSE[i] = root_mean_squared_error(Y_test, mean_prediction[i])\n","    \n","    R2Trn[i] = gaussian_process.score(X_train,Y_train)\n","    R2Test[i] = gaussian_process.score(X_test,Y_test)\n","    TrTime[i] = stop - start\n","    \n","    print(\"\\n\\n Training Time =\", \"%.0f\" % TrTime[i], \"sec\")"]},{"cell_type":"markdown","metadata":{},"source":["#### GPR Results & Evaluation"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Frequency Range: 10000 Hz ~ 5.012 Hz\n","Frequency Range: 10000 Hz ~ 5.012 Hz\n","Frequency Points: 34\n","Length Scale Range: (0.05, 1000000.0)\n","\n","MAE = 5.9997\n","MSE = 48.4616\n","RMSE = 6.9545\n","\n","R²(Test) = -0.0178\n","Total Training Time = 88 sec\n","\n","Error Metrics Table\n","+----------+-------+--------+-------+----------+-----------+\n","|   Fold # |   MAE |   RMSE |    R² |   R²(Tr) |   Tr Time |\n","+==========+=======+========+=======+==========+===========+\n","|        1 |  5.66 |   6.61 | -0.00 |    -0.00 |     11.04 |\n","+----------+-------+--------+-------+----------+-----------+\n","|        2 |  6.24 |   7.19 | -0.00 |    -0.00 |     26.21 |\n","+----------+-------+--------+-------+----------+-----------+\n","|        3 |  6.29 |   7.20 | -0.00 |    -0.00 |     10.56 |\n","+----------+-------+--------+-------+----------+-----------+\n","|        4 |  5.39 |   6.54 | -0.01 |    -0.00 |     22.39 |\n","+----------+-------+--------+-------+----------+-----------+\n","|        5 |  6.41 |   7.23 | -0.08 |    -0.00 |     17.75 |\n","+----------+-------+--------+-------+----------+-----------+\n","\n","Optimized kernel hyperparameters for each fold:\n","2.45**2 * 36.9**2 + WhiteKernel(noise_level=10)\n","11.3**2 * 7.99**2 + WhiteKernel(noise_level=10)\n","191**2 * 0.474**2 + WhiteKernel(noise_level=10)\n","4.02**2 * 22.4**2 + WhiteKernel(noise_level=10)\n","57**2 * 1.58**2 + WhiteKernel(noise_level=10)\n","\n","Fold 1\n","+---------+--------+-------+------------+-----------------+---------+\n","|   Cell# |   Temp |   SoC |   True SoH |   Predicted SoH |   Error |\n","+=========+========+=======+============+=================+=========+\n","|       2 |     15 |     5 |      95.05 |           90.26 |    4.79 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       2 |     15 |    20 |      95.05 |           90.26 |    4.79 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       2 |     15 |    50 |      95.05 |           90.26 |    4.79 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       2 |     15 |    70 |      95.05 |           90.26 |    4.79 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       2 |     15 |    95 |      95.05 |           90.26 |    4.79 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       2 |     25 |     5 |      95.05 |           90.26 |    4.79 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       2 |     25 |    20 |      95.05 |           90.26 |    4.79 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       2 |     25 |    50 |      95.05 |           90.26 |    4.79 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       2 |     25 |    70 |      95.05 |           90.26 |    4.79 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       2 |     25 |    95 |      95.05 |           90.26 |    4.79 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       2 |     35 |     5 |      95.05 |           90.26 |    4.79 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       2 |     35 |    20 |      95.05 |           90.26 |    4.79 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       2 |     35 |    50 |      95.05 |           90.26 |    4.79 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       2 |     35 |    70 |      95.05 |           90.26 |    4.79 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       2 |     35 |    95 |      95.05 |           90.26 |    4.79 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      12 |     15 |     5 |      90.95 |           90.26 |    0.69 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      12 |     15 |    20 |      90.95 |           90.26 |    0.69 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      12 |     15 |    50 |      90.95 |           90.26 |    0.69 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      12 |     15 |    70 |      90.95 |           90.26 |    0.69 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      12 |     15 |    95 |      90.95 |           90.26 |    0.69 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      12 |     25 |     5 |      90.95 |           90.26 |    0.69 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      12 |     25 |    20 |      90.95 |           90.26 |    0.69 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      12 |     25 |    50 |      90.95 |           90.26 |    0.69 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      12 |     25 |    70 |      90.95 |           90.26 |    0.69 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      12 |     25 |    95 |      90.95 |           90.26 |    0.69 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      12 |     35 |     5 |      90.95 |           90.26 |    0.69 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      12 |     35 |    20 |      90.95 |           90.26 |    0.69 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      12 |     35 |    50 |      90.95 |           90.26 |    0.69 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      12 |     35 |    70 |      90.95 |           90.26 |    0.69 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      12 |     35 |    95 |      90.95 |           90.26 |    0.69 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      15 |     15 |     5 |      81.02 |           90.26 |   -9.24 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      15 |     15 |    20 |      81.02 |           90.26 |   -9.24 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      15 |     15 |    50 |      81.02 |           90.26 |   -9.24 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      15 |     15 |    70 |      81.02 |           90.26 |   -9.24 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      15 |     15 |    95 |      81.02 |           90.26 |   -9.24 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      15 |     25 |     5 |      81.02 |           90.26 |   -9.24 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      15 |     25 |    20 |      81.02 |           90.26 |   -9.24 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      15 |     25 |    50 |      81.02 |           90.26 |   -9.24 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      15 |     25 |    70 |      81.02 |           90.26 |   -9.24 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      15 |     25 |    95 |      81.02 |           90.26 |   -9.24 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      15 |     35 |     5 |      81.02 |           90.26 |   -9.24 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      15 |     35 |    20 |      81.02 |           90.26 |   -9.24 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      15 |     35 |    50 |      81.02 |           90.26 |   -9.24 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      15 |     35 |    70 |      81.02 |           90.26 |   -9.24 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      15 |     35 |    95 |      81.02 |           90.26 |   -9.24 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      19 |     15 |     5 |      86.41 |           90.26 |   -3.85 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      19 |     15 |    20 |      86.41 |           90.26 |   -3.85 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      19 |     15 |    50 |      86.41 |           90.26 |   -3.85 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      19 |     15 |    70 |      86.41 |           90.26 |   -3.85 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      19 |     15 |    95 |      86.41 |           90.26 |   -3.85 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      19 |     25 |     5 |      86.41 |           90.26 |   -3.85 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      19 |     25 |    20 |      86.41 |           90.26 |   -3.85 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      19 |     25 |    50 |      86.41 |           90.26 |   -3.85 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      19 |     25 |    70 |      86.41 |           90.26 |   -3.85 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      19 |     25 |    95 |      86.41 |           90.26 |   -3.85 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      19 |     35 |     5 |      86.41 |           90.26 |   -3.85 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      19 |     35 |    20 |      86.41 |           90.26 |   -3.85 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      19 |     35 |    50 |      86.41 |           90.26 |   -3.85 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      19 |     35 |    70 |      86.41 |           90.26 |   -3.85 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      19 |     35 |    95 |      86.41 |           90.26 |   -3.85 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      28 |     15 |     5 |     100.00 |           90.26 |    9.74 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      28 |     15 |    20 |     100.00 |           90.26 |    9.74 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      28 |     15 |    50 |     100.00 |           90.26 |    9.74 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      28 |     15 |    70 |     100.00 |           90.26 |    9.74 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      28 |     15 |    95 |     100.00 |           90.26 |    9.74 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      28 |     25 |     5 |     100.00 |           90.26 |    9.74 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      28 |     25 |    20 |     100.00 |           90.26 |    9.74 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      28 |     25 |    50 |     100.00 |           90.26 |    9.74 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      28 |     25 |    70 |     100.00 |           90.26 |    9.74 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      28 |     25 |    95 |     100.00 |           90.26 |    9.74 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      28 |     35 |     5 |     100.00 |           90.26 |    9.74 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      28 |     35 |    20 |     100.00 |           90.26 |    9.74 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      28 |     35 |    50 |     100.00 |           90.26 |    9.74 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      28 |     35 |    70 |     100.00 |           90.26 |    9.74 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      28 |     35 |    95 |     100.00 |           90.26 |    9.74 |\n","+---------+--------+-------+------------+-----------------+---------+\n","\n","Fold 2\n","+---------+--------+-------+------------+-----------------+---------+\n","|   Cell# |   Temp |   SoC |   True SoH |   Predicted SoH |   Error |\n","+=========+========+=======+============+=================+=========+\n","|       3 |     15 |     5 |      96.21 |           90.35 |    5.86 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       3 |     15 |    20 |      96.21 |           90.35 |    5.86 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       3 |     15 |    50 |      96.21 |           90.35 |    5.86 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       3 |     15 |    70 |      96.21 |           90.35 |    5.86 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       3 |     15 |    95 |      96.21 |           90.35 |    5.86 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       3 |     25 |     5 |      96.21 |           90.35 |    5.86 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       3 |     25 |    20 |      96.21 |           90.35 |    5.86 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       3 |     25 |    50 |      96.21 |           90.35 |    5.86 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       3 |     25 |    70 |      96.21 |           90.35 |    5.86 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       3 |     25 |    95 |      96.21 |           90.35 |    5.86 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       3 |     35 |     5 |      96.21 |           90.35 |    5.86 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       3 |     35 |    20 |      96.21 |           90.35 |    5.86 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       3 |     35 |    50 |      96.21 |           90.35 |    5.86 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       3 |     35 |    70 |      96.21 |           90.35 |    5.86 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       3 |     35 |    95 |      96.21 |           90.35 |    5.86 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      17 |     15 |     5 |      80.46 |           90.35 |   -9.89 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      17 |     15 |    20 |      80.46 |           90.35 |   -9.89 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      17 |     15 |    50 |      80.46 |           90.35 |   -9.89 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      17 |     15 |    70 |      80.46 |           90.35 |   -9.89 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      17 |     15 |    95 |      80.46 |           90.35 |   -9.89 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      17 |     25 |     5 |      80.46 |           90.35 |   -9.89 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      17 |     25 |    20 |      80.46 |           90.35 |   -9.89 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      17 |     25 |    50 |      80.46 |           90.35 |   -9.89 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      17 |     25 |    70 |      80.46 |           90.35 |   -9.89 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      17 |     25 |    95 |      80.46 |           90.35 |   -9.89 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      17 |     35 |     5 |      80.46 |           90.35 |   -9.89 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      17 |     35 |    20 |      80.46 |           90.35 |   -9.89 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      17 |     35 |    50 |      80.46 |           90.35 |   -9.89 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      17 |     35 |    70 |      80.46 |           90.35 |   -9.89 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      17 |     35 |    95 |      80.46 |           90.35 |   -9.89 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      20 |     15 |     5 |      84.58 |           90.35 |   -5.77 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      20 |     15 |    20 |      84.58 |           90.35 |   -5.77 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      20 |     15 |    50 |      84.58 |           90.35 |   -5.77 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      20 |     15 |    70 |      84.58 |           90.35 |   -5.77 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      20 |     15 |    95 |      84.58 |           90.35 |   -5.77 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      20 |     25 |     5 |      84.58 |           90.35 |   -5.77 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      20 |     25 |    20 |      84.58 |           90.35 |   -5.77 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      20 |     25 |    50 |      84.58 |           90.35 |   -5.77 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      20 |     25 |    70 |      84.58 |           90.35 |   -5.77 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      20 |     25 |    95 |      84.58 |           90.35 |   -5.77 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      20 |     35 |     5 |      84.58 |           90.35 |   -5.77 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      20 |     35 |    20 |      84.58 |           90.35 |   -5.77 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      20 |     35 |    50 |      84.58 |           90.35 |   -5.77 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      20 |     35 |    70 |      84.58 |           90.35 |   -5.77 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      20 |     35 |    95 |      84.58 |           90.35 |   -5.77 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     15 |     5 |      90.39 |           90.35 |    0.04 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     15 |    20 |      90.39 |           90.35 |    0.04 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     15 |    50 |      90.39 |           90.35 |    0.04 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     15 |    70 |      90.39 |           90.35 |    0.04 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     15 |    95 |      90.39 |           90.35 |    0.04 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     25 |     5 |      90.39 |           90.35 |    0.04 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     25 |    20 |      90.39 |           90.35 |    0.04 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     25 |    50 |      90.39 |           90.35 |    0.04 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     25 |    70 |      90.39 |           90.35 |    0.04 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     25 |    95 |      90.39 |           90.35 |    0.04 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     35 |     5 |      90.39 |           90.35 |    0.04 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     35 |    20 |      90.39 |           90.35 |    0.04 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     35 |    50 |      90.39 |           90.35 |    0.04 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     35 |    70 |      90.39 |           90.35 |    0.04 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     35 |    95 |      90.39 |           90.35 |    0.04 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      29 |     15 |     5 |     100.00 |           90.35 |    9.65 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      29 |     15 |    20 |     100.00 |           90.35 |    9.65 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      29 |     15 |    50 |     100.00 |           90.35 |    9.65 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      29 |     15 |    70 |     100.00 |           90.35 |    9.65 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      29 |     15 |    95 |     100.00 |           90.35 |    9.65 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      29 |     25 |     5 |     100.00 |           90.35 |    9.65 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      29 |     25 |    20 |     100.00 |           90.35 |    9.65 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      29 |     25 |    50 |     100.00 |           90.35 |    9.65 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      29 |     25 |    70 |     100.00 |           90.35 |    9.65 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      29 |     25 |    95 |     100.00 |           90.35 |    9.65 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      29 |     35 |     5 |     100.00 |           90.35 |    9.65 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      29 |     35 |    20 |     100.00 |           90.35 |    9.65 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      29 |     35 |    50 |     100.00 |           90.35 |    9.65 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      29 |     35 |    70 |     100.00 |           90.35 |    9.65 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      29 |     35 |    95 |     100.00 |           90.35 |    9.65 |\n","+---------+--------+-------+------------+-----------------+---------+\n","\n","Fold 3\n","+---------+--------+-------+------------+-----------------+---------+\n","|   Cell# |   Temp |   SoC |   True SoH |   Predicted SoH |   Error |\n","+=========+========+=======+============+=================+=========+\n","|       4 |     15 |     5 |      96.10 |           90.38 |    5.72 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       4 |     15 |    20 |      96.10 |           90.38 |    5.72 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       4 |     15 |    50 |      96.10 |           90.38 |    5.72 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       4 |     15 |    70 |      96.10 |           90.38 |    5.72 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       4 |     15 |    95 |      96.10 |           90.38 |    5.72 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       4 |     25 |     5 |      96.10 |           90.38 |    5.72 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       4 |     25 |    20 |      96.10 |           90.38 |    5.72 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       4 |     25 |    50 |      96.10 |           90.38 |    5.72 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       4 |     25 |    70 |      96.10 |           90.38 |    5.72 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       4 |     25 |    95 |      96.10 |           90.38 |    5.72 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       4 |     35 |     5 |      96.10 |           90.38 |    5.72 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       4 |     35 |    20 |      96.10 |           90.38 |    5.72 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       4 |     35 |    50 |      96.10 |           90.38 |    5.72 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       4 |     35 |    70 |      96.10 |           90.38 |    5.72 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       4 |     35 |    95 |      96.10 |           90.38 |    5.72 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      14 |     15 |     5 |      90.37 |           90.38 |   -0.01 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      14 |     15 |    20 |      90.37 |           90.38 |   -0.01 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      14 |     15 |    50 |      90.37 |           90.38 |   -0.01 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      14 |     15 |    70 |      90.37 |           90.38 |   -0.01 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      14 |     15 |    95 |      90.37 |           90.38 |   -0.01 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      14 |     25 |     5 |      90.37 |           90.38 |   -0.01 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      14 |     25 |    20 |      90.37 |           90.38 |   -0.01 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      14 |     25 |    50 |      90.37 |           90.38 |   -0.01 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      14 |     25 |    70 |      90.37 |           90.38 |   -0.01 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      14 |     25 |    95 |      90.37 |           90.38 |   -0.01 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      14 |     35 |     5 |      90.37 |           90.38 |   -0.01 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      14 |     35 |    20 |      90.37 |           90.38 |   -0.01 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      14 |     35 |    50 |      90.37 |           90.38 |   -0.01 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      14 |     35 |    70 |      90.37 |           90.38 |   -0.01 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      14 |     35 |    95 |      90.37 |           90.38 |   -0.01 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      18 |     15 |     5 |      80.90 |           90.38 |   -9.48 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      18 |     15 |    20 |      80.90 |           90.38 |   -9.48 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      18 |     15 |    50 |      80.90 |           90.38 |   -9.48 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      18 |     15 |    70 |      80.90 |           90.38 |   -9.48 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      18 |     15 |    95 |      80.90 |           90.38 |   -9.48 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      18 |     25 |     5 |      80.90 |           90.38 |   -9.48 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      18 |     25 |    20 |      80.90 |           90.38 |   -9.48 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      18 |     25 |    50 |      80.90 |           90.38 |   -9.48 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      18 |     25 |    70 |      80.90 |           90.38 |   -9.48 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      18 |     25 |    95 |      80.90 |           90.38 |   -9.48 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      18 |     35 |     5 |      80.90 |           90.38 |   -9.48 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      18 |     35 |    20 |      80.90 |           90.38 |   -9.48 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      18 |     35 |    50 |      80.90 |           90.38 |   -9.48 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      18 |     35 |    70 |      80.90 |           90.38 |   -9.48 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      18 |     35 |    95 |      80.90 |           90.38 |   -9.48 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      21 |     15 |     5 |      83.75 |           90.38 |   -6.63 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      21 |     15 |    20 |      83.75 |           90.38 |   -6.63 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      21 |     15 |    50 |      83.75 |           90.38 |   -6.63 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      21 |     15 |    70 |      83.75 |           90.38 |   -6.63 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      21 |     15 |    95 |      83.75 |           90.38 |   -6.63 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      21 |     25 |     5 |      83.75 |           90.38 |   -6.63 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      21 |     25 |    20 |      83.75 |           90.38 |   -6.63 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      21 |     25 |    50 |      83.75 |           90.38 |   -6.63 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      21 |     25 |    70 |      83.75 |           90.38 |   -6.63 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      21 |     25 |    95 |      83.75 |           90.38 |   -6.63 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      21 |     35 |     5 |      83.75 |           90.38 |   -6.63 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      21 |     35 |    20 |      83.75 |           90.38 |   -6.63 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      21 |     35 |    50 |      83.75 |           90.38 |   -6.63 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      21 |     35 |    70 |      83.75 |           90.38 |   -6.63 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      21 |     35 |    95 |      83.75 |           90.38 |   -6.63 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      30 |     15 |     5 |     100.00 |           90.38 |    9.62 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      30 |     15 |    20 |     100.00 |           90.38 |    9.62 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      30 |     15 |    50 |     100.00 |           90.38 |    9.62 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      30 |     15 |    70 |     100.00 |           90.38 |    9.62 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      30 |     15 |    95 |     100.00 |           90.38 |    9.62 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      30 |     25 |     5 |     100.00 |           90.38 |    9.62 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      30 |     25 |    20 |     100.00 |           90.38 |    9.62 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      30 |     25 |    50 |     100.00 |           90.38 |    9.62 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      30 |     25 |    70 |     100.00 |           90.38 |    9.62 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      30 |     25 |    95 |     100.00 |           90.38 |    9.62 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      30 |     35 |     5 |     100.00 |           90.38 |    9.62 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      30 |     35 |    20 |     100.00 |           90.38 |    9.62 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      30 |     35 |    50 |     100.00 |           90.38 |    9.62 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      30 |     35 |    70 |     100.00 |           90.38 |    9.62 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      30 |     35 |    95 |     100.00 |           90.38 |    9.62 |\n","+---------+--------+-------+------------+-----------------+---------+\n","\n","Fold 4\n","+---------+--------+-------+------------+-----------------+---------+\n","|   Cell# |   Temp |   SoC |   True SoH |   Predicted SoH |   Error |\n","+=========+========+=======+============+=================+=========+\n","|       5 |     15 |     5 |      95.29 |           90.22 |    5.07 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       5 |     15 |    20 |      95.29 |           90.22 |    5.07 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       5 |     15 |    50 |      95.29 |           90.22 |    5.07 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       5 |     15 |    70 |      95.29 |           90.22 |    5.07 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       5 |     15 |    95 |      95.29 |           90.22 |    5.07 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       5 |     25 |     5 |      95.29 |           90.22 |    5.07 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       5 |     25 |    20 |      95.29 |           90.22 |    5.07 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       5 |     25 |    50 |      95.29 |           90.22 |    5.07 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       5 |     25 |    70 |      95.29 |           90.22 |    5.07 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       5 |     25 |    95 |      95.29 |           90.22 |    5.07 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       5 |     35 |     5 |      95.29 |           90.22 |    5.07 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       5 |     35 |    20 |      95.29 |           90.22 |    5.07 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       5 |     35 |    50 |      95.29 |           90.22 |    5.07 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       5 |     35 |    70 |      95.29 |           90.22 |    5.07 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       5 |     35 |    95 |      95.29 |           90.22 |    5.07 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      22 |     15 |     5 |      81.00 |           90.22 |   -9.22 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      22 |     15 |    20 |      81.00 |           90.22 |   -9.22 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      22 |     15 |    50 |      81.00 |           90.22 |   -9.22 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      22 |     15 |    70 |      81.00 |           90.22 |   -9.22 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      22 |     15 |    95 |      81.00 |           90.22 |   -9.22 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      22 |     25 |     5 |      81.00 |           90.22 |   -9.22 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      22 |     25 |    20 |      81.00 |           90.22 |   -9.22 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      22 |     25 |    50 |      81.00 |           90.22 |   -9.22 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      22 |     25 |    70 |      81.00 |           90.22 |   -9.22 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      22 |     25 |    95 |      81.00 |           90.22 |   -9.22 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      22 |     35 |     5 |      81.00 |           90.22 |   -9.22 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      22 |     35 |    20 |      81.00 |           90.22 |   -9.22 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      22 |     35 |    50 |      81.00 |           90.22 |   -9.22 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      22 |     35 |    70 |      81.00 |           90.22 |   -9.22 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      22 |     35 |    95 |      81.00 |           90.22 |   -9.22 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     15 |     5 |      90.39 |           90.22 |    0.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     15 |    20 |      90.39 |           90.22 |    0.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     15 |    50 |      90.39 |           90.22 |    0.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     15 |    70 |      90.39 |           90.22 |    0.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     15 |    95 |      90.39 |           90.22 |    0.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     25 |     5 |      90.39 |           90.22 |    0.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     25 |    20 |      90.39 |           90.22 |    0.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     25 |    50 |      90.39 |           90.22 |    0.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     25 |    70 |      90.39 |           90.22 |    0.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     25 |    95 |      90.39 |           90.22 |    0.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     35 |     5 |      90.39 |           90.22 |    0.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     35 |    20 |      90.39 |           90.22 |    0.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     35 |    50 |      90.39 |           90.22 |    0.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     35 |    70 |      90.39 |           90.22 |    0.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      23 |     35 |    95 |      90.39 |           90.22 |    0.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      25 |     15 |     5 |      87.49 |           90.22 |   -2.73 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      25 |     15 |    20 |      87.49 |           90.22 |   -2.73 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      25 |     15 |    50 |      87.49 |           90.22 |   -2.73 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      25 |     15 |    70 |      87.49 |           90.22 |   -2.73 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      25 |     15 |    95 |      87.49 |           90.22 |   -2.73 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      25 |     25 |     5 |      87.49 |           90.22 |   -2.73 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      25 |     25 |    20 |      87.49 |           90.22 |   -2.73 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      25 |     25 |    50 |      87.49 |           90.22 |   -2.73 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      25 |     25 |    70 |      87.49 |           90.22 |   -2.73 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      25 |     25 |    95 |      87.49 |           90.22 |   -2.73 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      25 |     35 |     5 |      87.49 |           90.22 |   -2.73 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      25 |     35 |    20 |      87.49 |           90.22 |   -2.73 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      25 |     35 |    50 |      87.49 |           90.22 |   -2.73 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      25 |     35 |    70 |      87.49 |           90.22 |   -2.73 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      25 |     35 |    95 |      87.49 |           90.22 |   -2.73 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      32 |     15 |     5 |     100.00 |           90.22 |    9.78 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      32 |     15 |    20 |     100.00 |           90.22 |    9.78 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      32 |     15 |    50 |     100.00 |           90.22 |    9.78 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      32 |     15 |    70 |     100.00 |           90.22 |    9.78 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      32 |     15 |    95 |     100.00 |           90.22 |    9.78 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      32 |     25 |     5 |     100.00 |           90.22 |    9.78 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      32 |     25 |    20 |     100.00 |           90.22 |    9.78 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      32 |     25 |    50 |     100.00 |           90.22 |    9.78 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      32 |     25 |    70 |     100.00 |           90.22 |    9.78 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      32 |     25 |    95 |     100.00 |           90.22 |    9.78 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      32 |     35 |     5 |     100.00 |           90.22 |    9.78 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      32 |     35 |    20 |     100.00 |           90.22 |    9.78 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      32 |     35 |    50 |     100.00 |           90.22 |    9.78 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      32 |     35 |    70 |     100.00 |           90.22 |    9.78 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      32 |     35 |    95 |     100.00 |           90.22 |    9.78 |\n","+---------+--------+-------+------------+-----------------+---------+\n","\n","Fold 5\n","+---------+--------+-------+------------+-----------------+---------+\n","|   Cell# |   Temp |   SoC |   True SoH |   Predicted SoH |   Error |\n","+=========+========+=======+============+=================+=========+\n","|       6 |     15 |     5 |      95.20 |           90.03 |    5.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       6 |     15 |    20 |      95.20 |           90.03 |    5.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       6 |     15 |    50 |      95.20 |           90.03 |    5.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       6 |     15 |    70 |      95.20 |           90.03 |    5.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       6 |     15 |    95 |      95.20 |           90.03 |    5.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       6 |     25 |     5 |      95.20 |           90.03 |    5.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       6 |     25 |    20 |      95.20 |           90.03 |    5.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       6 |     25 |    50 |      95.20 |           90.03 |    5.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       6 |     25 |    70 |      95.20 |           90.03 |    5.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       6 |     25 |    95 |      95.20 |           90.03 |    5.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       6 |     35 |     5 |      95.20 |           90.03 |    5.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       6 |     35 |    20 |      95.20 |           90.03 |    5.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       6 |     35 |    50 |      95.20 |           90.03 |    5.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       6 |     35 |    70 |      95.20 |           90.03 |    5.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|       6 |     35 |    95 |      95.20 |           90.03 |    5.17 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      13 |     15 |     5 |      91.53 |           90.03 |    1.50 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      13 |     15 |    20 |      91.53 |           90.03 |    1.50 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      13 |     15 |    50 |      91.53 |           90.03 |    1.50 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      13 |     15 |    70 |      91.53 |           90.03 |    1.50 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      13 |     15 |    95 |      91.53 |           90.03 |    1.50 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      13 |     25 |     5 |      91.53 |           90.03 |    1.50 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      13 |     25 |    20 |      91.53 |           90.03 |    1.50 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      13 |     25 |    50 |      91.53 |           90.03 |    1.50 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      13 |     25 |    70 |      91.53 |           90.03 |    1.50 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      13 |     25 |    95 |      91.53 |           90.03 |    1.50 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      13 |     35 |     5 |      91.53 |           90.03 |    1.50 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      13 |     35 |    20 |      91.53 |           90.03 |    1.50 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      13 |     35 |    50 |      91.53 |           90.03 |    1.50 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      13 |     35 |    70 |      91.53 |           90.03 |    1.50 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      13 |     35 |    95 |      91.53 |           90.03 |    1.50 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      24 |     15 |     5 |      81.04 |           90.03 |   -8.99 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      24 |     15 |    20 |      81.04 |           90.03 |   -8.99 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      24 |     15 |    50 |      81.04 |           90.03 |   -8.99 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      24 |     15 |    70 |      81.04 |           90.03 |   -8.99 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      24 |     15 |    95 |      81.04 |           90.03 |   -8.99 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      24 |     25 |     5 |      81.04 |           90.03 |   -8.99 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      24 |     25 |    20 |      81.04 |           90.03 |   -8.99 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      24 |     25 |    50 |      81.04 |           90.03 |   -8.99 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      24 |     25 |    70 |      81.04 |           90.03 |   -8.99 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      24 |     25 |    95 |      81.04 |           90.03 |   -8.99 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      24 |     35 |     5 |      81.04 |           90.03 |   -8.99 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      24 |     35 |    20 |      81.04 |           90.03 |   -8.99 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      24 |     35 |    50 |      81.04 |           90.03 |   -8.99 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      24 |     35 |    70 |      81.04 |           90.03 |   -8.99 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      24 |     35 |    95 |      81.04 |           90.03 |   -8.99 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      31 |     15 |     5 |     100.00 |           90.03 |    9.97 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      31 |     15 |    20 |     100.00 |           90.03 |    9.97 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      31 |     15 |    50 |     100.00 |           90.03 |    9.97 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      31 |     15 |    70 |     100.00 |           90.03 |    9.97 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      31 |     15 |    95 |     100.00 |           90.03 |    9.97 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      31 |     25 |     5 |     100.00 |           90.03 |    9.97 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      31 |     25 |    20 |     100.00 |           90.03 |    9.97 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      31 |     25 |    50 |     100.00 |           90.03 |    9.97 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      31 |     25 |    70 |     100.00 |           90.03 |    9.97 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      31 |     25 |    95 |     100.00 |           90.03 |    9.97 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      31 |     35 |     5 |     100.00 |           90.03 |    9.97 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      31 |     35 |    20 |     100.00 |           90.03 |    9.97 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      31 |     35 |    50 |     100.00 |           90.03 |    9.97 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      31 |     35 |    70 |     100.00 |           90.03 |    9.97 |\n","+---------+--------+-------+------------+-----------------+---------+\n","|      31 |     35 |    95 |     100.00 |           90.03 |    9.97 |\n","+---------+--------+-------+------------+-----------------+---------+\n"]}],"source":["from tabulate import tabulate\n","\n","FPx_numbers = [value[2:] for value in FPx]              # Just to remove Fx from frequency\n","FPy_numbers = [value[2:] for value in FPy]              # Just to remove Fy from frequency\n","\n","# Tunable Characteristics\n","print(\"Frequency Range:\", FPx_numbers[0], \"Hz ~\", FPx_numbers[-1], \"Hz\")\n","print(\"Frequency Range:\", FPy_numbers[0], \"Hz ~\", FPy_numbers[-1], \"Hz\")\n","print(\"Frequency Points:\", \"%.1d\" % np.shape(FPx))\n","print(\"Length Scale Range:\", MlengthScaleBounds[0])\n","\n","# Calculating the Average Error Metrics\n","print(\"\\nMAE =\", \"%.4f\" % np.mean(MAE))\n","print(\"MSE =\",  \"%.4f\" % np.mean(MSE))\n","print(\"RMSE =\", \"%.4f\" % np.mean(RMSE))\n","print(\"\\nR²(Test) =\", \"%.4f\" % np.mean(R2Test))\n","print(\"Total Training Time =\", \"%.0f\" % sum(TrTime), \"sec\")\n","\n","# Creating Table for error Metrics for each Fold\n","print(\"\\nError Metrics Table\")\n","data = list(zip([\"1\", \"2\", \"3\", \"4\", \"5\"], MAE, RMSE, R2Test, R2Trn, TrTime))\n","# Define the headers\n","headers = [\"Fold #\",\"MAE\", \"RMSE\", \"R²\", \"R²(Tr)\", \"Tr Time\"]\n","# Create and print the table\n","table = tabulate(data, headers, tablefmt=\"grid\", floatfmt=\".2f\")\n","print(table)\n","\n","# Printing the Optimized Hyperparameters for each Fold\n","print(\"\\nOptimized kernel hyperparameters for each fold:\")\n","for i in range(len(test)):\n","    print(kernelHP[i])\n","\n","# Printing table for individual Prediction\n","for i in range(len(test)):\n","    print(\"\\nFold\",i+1)\n","    # Combine the arrays into rows\n","    data = list(zip(sfp[test[i]]['Cell_Name'],sfp[test[i]]['Temp'],sfp[test[i]]['SoC'],sfp[test[i]]['SoH_Actual'], mean_prediction[i], Error[i]) )\n","    # Define the headers\n","    headers = [\"Cell#\",\"Temp\",\"SoC\",\"True SoH\", \"Predicted SoH\", \"Error\"]\n","    # Create and print the table\n","    table = tabulate(data, headers, tablefmt=\"grid\", floatfmt=\".2f\")\n","    print(table)"]},{"cell_type":"markdown","metadata":{},"source":["#### Plotting the Results"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"ename":"KeyError","evalue":"\"None of [Index([               (True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, ...),\\n       (False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...),\\n       (False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...),\\n       (False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...),\\n                 (False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, ...)],\\n      dtype='object')] are in the [columns]\"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[1;32mIn[38], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m fig, (ax1, ax2) \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Subplot (a): True SoH & Predicted SoH vs Test Points\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m ax1\u001b[38;5;241m.\u001b[39mplot(Testpoints, \u001b[43msfp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCell_Name\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbo\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue SoH\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m ax1\u001b[38;5;241m.\u001b[39mplot(Testpoints, mean_prediction, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgo\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted SoH\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m ax1\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Points\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[1;32mc:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n","File \u001b[1;32mc:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Ahmad Faris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[1;31mKeyError\u001b[0m: \"None of [Index([               (True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, ...),\\n       (False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...),\\n       (False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...),\\n       (False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, ...),\\n                 (False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, ...)],\\n      dtype='object')] are in the [columns]\""]},{"data":{"image/png":"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","text/plain":["<Figure size 1500x600 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["Testpoints = np.arange(1, 360+1)  # Test Points Numbering\n","\n","# Create a figure with 2 subplots\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n","\n","# Subplot (a): True SoH & Predicted SoH vs Test Points\n","ax1.plot(Testpoints, sfp[test]['Cell_Name'], 'bo', label='True SoH')\n","ax1.plot(Testpoints, mean_prediction, 'go', label='Predicted SoH')\n","ax1.set_xlabel('Test Points')\n","ax1.set_ylabel('SoH (%)')\n","ax1.legend()\n","ax1.grid(True)\n","ax1.set_title('True SoH & Predicted SoH vs Test Points')\n","\n","# Subplot (b): True SoH vs Predicted SoH\n","ax2.plot(Y_test, mean_prediction, 'ro', label='Observation')\n","ax2.plot([80, 100], [80, 100], 'k-', label='Perfect Prediction')\n","ax2.set_xlabel('True SoH (%)')\n","ax2.set_ylabel('Predicted SoH (%)')\n","ax2.legend()\n","ax2.grid(True)\n","ax2.set_title('True SoH vs Predicted SoH')\n","\n","# Show the plot\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Plotting Seperate EIS Nyquist Plots"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x800 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["(360, 61)\n"]}],"source":["FPa = FP61\n","FPax = [value for value in FPa if value.startswith('Fx')]\n","FPay = [value for value in FPa if value.startswith('Fy')]\n","\n","X_Nyquist = np.asanyarray(sfp[FPax])\n","Y_Nyquist = np.asanyarray(sfp[FPay])\n","\n","PlotNo = 210\n","\n","plt.figure(figsize=(10, 8))\n","for i in range(sfp.shape[0]):\n","    plt.plot(X_Nyquist[PlotNo], (-1)*Y_Nyquist[PlotNo], marker='o', label=f'Row {i}')\n","\n","plt.xlabel('Re (Z) Ohm')\n","plt.ylabel('-Im (Z) Ohm')\n","plt.title('Comparison of All Rows')\n","# plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","print(np.shape(X_Nyquist))"]},{"cell_type":"markdown","metadata":{},"source":["### ---------------------End of Code---------------------"]},{"cell_type":"markdown","metadata":{},"source":["### ______________________________________________________________________"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":0}
